{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use the state evolution package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a simple example of how to use the state evolution package with custom teacher-student covariance rmrices. The class has three components:\n",
    "- `data_model`: this class defines everything concerning the generative model for data - i.e. it initialises the covariances $\\Psi, \\Phi, \\Omega$ and the teacher weights $\\theta_{0}$ and pre-computes all the quantities required for the state evolution.\n",
    "- `model`: this class defines the task. It basically contains the updates for the overlaps and their conjugates. So far, we have implemented ridge and logistic regression.\n",
    "- `algorithms`: this class defines the iterator for the state evolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from state_evolution.models.logistic_regression import LogisticRegression # logistic regression task\n",
    "from state_evolution.algorithms.state_evolution import StateEvolution # Standard SP iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Custom data model: fixed sample complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a simple example where we input the covariances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from state_evolution.data_models.custom import Custom # Custom data model. You input the covariances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the Gaussian covariate model is defined by a teacher-student model with:\n",
    "- Teacher : $y = f_{0}(\\theta_{0}\\cdot u)$, $\\theta_{0}\\sim\\mathcal{N}(0,\\rm{I}_{p})$\n",
    "- Student : $\\hat{y} = \\hat{f}(w\\cdot v)$\n",
    "where $z\\in\\mathbb{R}^{p}$ and $v\\in\\mathbb{R}^{d}$ are jointly Gaussian variables with covariances\n",
    "$$ \\Psi = \\mathbb{E}uu^{\\top}\\in\\mathbb{R}^{p\\times p}, \\qquad \\Phi = \\mathbb{E}uv^{\\top}\\in\\mathbb{R}^{p\\times d}, \\qquad \\Omega = \\mathbb{E}vv^{\\top}\\in\\mathbb{R}^{v\\times v}\n",
    "$$.\n",
    "\n",
    "The class `Custom` takes as input the three covariance matrices that define an instance of the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, let's look at a simple model of a Gaussian teacher $\\theta_{0}\\sim\\mathcal{N}(0,\\rm{I}_{p})$ and both the teacher and student are Random Feature models on Gaussian i.i.d. data, with different dimensions and activation functions:\n",
    "$$\n",
    "u = \\rm{sign}\\left(\\frac{1}{\\sqrt{D}}\\bar{\\rm{F}}c\\right), \\qquad v = \\rm{erf}\\left(\\frac{1}{\\sqrt{D}}\\rm{F}c\\right), \\qquad c\\sim\\mathcal{N}(0,\\rm{I}_{D})\n",
    "$$\n",
    "\n",
    "In this case recall that the covariances can be computed analytically, and are given by:\n",
    "\n",
    " \\begin{align}\n",
    " \\Psi = \\bar{\\kappa}_{1}^2 \\bar{\\rm{F}}\\bar{\\rm{F}}^{\\top}+\\bar{\\kappa}_{\\star}^2\\rm{I}_{p}, && \\Phi = \\bar{\\kappa}_{1}\\kappa_{1} \\bar{\\rm{F}}\\rm{F}^{\\top}, && \\Omega = \\kappa_{1}^2 \\rm{F}\\rm{F}^{\\top}+\\kappa_{\\star}^2\\rm{I}_{d}\n",
    " \\end{align}\n",
    " \n",
    "with $\\kappa_{1} \\equiv \\mathbb{E}\\left[\\xi\\sigma(\\xi)\\right]$ and $\\kappa_{\\star}^2 \\equiv \\mathbb{E}\\left[\\sigma(\\xi)\\right]^2-\\kappa_{1}^2$ for $\\xi\\sim\\mathcal{N}(0,1)$ (idem for the bar). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "COEFICIENTS = {'relu': (1/np.sqrt(2*np.pi), 0.5, np.sqrt((np.pi-2)/(4*np.pi))), \n",
    "               'erf': (0, 2/np.sqrt(3*np.pi), 0.200364), 'tanh': (0, 0.605706, 0.165576),\n",
    "               'sign': (0, np.sqrt(2/np.pi), np.sqrt(1-2/np.pi))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 1000 # dimension of c\n",
    "d = 2000 # dimension of x\n",
    "p = 1000 # dimension of k\n",
    "\n",
    "F_teacher = np.random.normal(0,1, (p,D)) / np.sqrt(D) # teacher random projection\n",
    "F_student = np.random.normal(0,1, (d,D)) / np.sqrt(D) # student random projection\n",
    "\n",
    "# Coefficients\n",
    "_, kappa1_teacher, kappastar_teacher = COEFICIENTS['sign']\n",
    "_, kappa1_student, kappastar_student = COEFICIENTS['erf']\n",
    "\n",
    "# Covariances\n",
    "Psi = (kappa1_teacher**2 * F_teacher @ F_teacher.T + kappastar_teacher**2 * np.identity(p))\n",
    "Omega = (kappa1_student**2 * F_student @ F_student.T + kappastar_student**2 * np.identity(d))\n",
    "Phi = kappa1_teacher * kappa1_student * F_teacher @ F_student.T \n",
    "\n",
    "# Teacher weights\n",
    "theta = np.random.normal(0,1, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our covariances, we can create our instance of `Custom`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model = Custom(teacher_teacher_cov = Psi, \n",
    "                    student_student_cov = Omega, \n",
    "                    teacher_student_cov = Phi,\n",
    "                    teacher_weights = theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to load our task. Let's look at logistic regression. The `model` class takes as an input the sample complexity $\\alpha = n/d$ and the $\\ell_2$ regularisation $\\lambda>0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = LogisticRegression(sample_complexity = 0.5,\n",
    "                          regularisation= 0.01,\n",
    "                          data_model = data_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All that is left is to initialise the saddle-point equation iterator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = StateEvolution(model = task,\n",
    "                    initialisation = 'uninformed',\n",
    "                    tolerance = 1e-7,\n",
    "                    damping = 0.5,\n",
    "                    verbose = True,\n",
    "                    max_steps = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can simply iterate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 0, diff: 478.0045013006251, self overlaps: 0.048412094609408575, teacher-student overlap: 0.051274874532115336\n",
      "t: 1, diff: 240.0002170073386, self overlaps: 0.15043222499943218, teacher-student overlap: 0.10913022451675058\n",
      "t: 2, diff: 121.54556186933097, self overlaps: 0.3644023939495723, teacher-student overlap: 0.18324061599016236\n",
      "t: 3, diff: 62.82752400014198, self overlaps: 0.7400197739562355, teacher-student overlap: 0.27438069344523214\n",
      "t: 4, diff: 33.70151952262598, self overlaps: 1.2750247609456742, teacher-student overlap: 0.3754082520564553\n",
      "t: 5, diff: 19.01417382856816, self overlaps: 1.9125382760019016, teacher-student overlap: 0.47590581496745876\n",
      "t: 6, diff: 11.323818303388515, self overlaps: 2.584600622487235, teacher-student overlap: 0.5678099979836926\n",
      "t: 7, diff: 7.084060451405307, self overlaps: 3.242597129663954, teacher-student overlap: 0.6473035545865558\n",
      "t: 8, diff: 4.615815754692549, self overlaps: 3.858580282412054, teacher-student overlap: 0.7137041196847345\n",
      "t: 9, diff: 3.103982249590652, self overlaps: 4.417601569115307, teacher-student overlap: 0.7679200654517726\n",
      "t: 10, diff: 2.135835959106487, self overlaps: 4.912247908544765, teacher-student overlap: 0.8114661766273072\n",
      "t: 11, diff: 1.4925157640998834, self overlaps: 5.340035580471168, teacher-student overlap: 0.845979421544576\n",
      "t: 12, diff: 1.0525106935305661, self overlaps: 5.702139778045101, teacher-student overlap: 0.8730109511125113\n",
      "t: 13, diff: 0.7452035241673747, self overlaps: 6.002496096831333, teacher-student overlap: 0.89394756351705\n",
      "t: 14, diff: 0.5276243148551063, self overlaps: 6.246945931260999, teacher-student overlap: 0.9099895149371242\n",
      "t: 15, diff: 0.3724168605271977, self overlaps: 6.442411942682538, teacher-student overlap: 0.9221524186418196\n",
      "t: 16, diff: 0.26141984920072636, self overlaps: 6.596177234421498, teacher-student overlap: 0.931279756046649\n",
      "t: 17, diff: 0.18213987188598058, self overlaps: 6.715327960177465, teacher-student overlap: 0.9380602986010753\n",
      "t: 18, diff: 0.1257463063636206, self overlaps: 6.806377634958627, teacher-student overlap: 0.9430476283184934\n",
      "t: 19, diff: 0.08588289874461363, self overlaps: 6.875057334717282, teacher-student overlap: 0.9466800699916853\n",
      "t: 20, diff: 0.057927439402206016, self overlaps: 6.9262369539693935, teacher-student overlap: 0.9492998365076148\n",
      "t: 21, diff: 0.04063841581997463, self overlaps: 6.96393826550465, teacher-student overlap: 0.9511705940702528\n",
      "t: 22, diff: 0.03242069308497331, self overlaps: 6.991404571207648, teacher-student overlap: 0.952492991494436\n",
      "t: 23, diff: 0.025345789106441252, self overlaps: 7.011198877232864, teacher-student overlap: 0.9534179410465977\n",
      "t: 24, diff: 0.019481250201663025, self overlaps: 7.025311477360345, teacher-student overlap: 0.9540577008988178\n",
      "t: 25, diff: 0.014754895319857741, self overlaps: 7.035264162826866, teacher-student overlap: 0.9544948867293654\n",
      "t: 26, diff: 0.011029278987269908, self overlaps: 7.042204507919344, teacher-student overlap: 0.9547896762680015\n",
      "t: 27, diff: 0.008145580663835084, self overlaps: 7.046986977474377, teacher-student overlap: 0.9549854591046616\n",
      "t: 28, diff: 0.005947979053085972, self overlaps: 7.050240268079584, teacher-student overlap: 0.9551131998673309\n",
      "t: 29, diff: 0.004296229194397871, self overlaps: 7.052421938491225, teacher-student overlap: 0.9551947792466531\n",
      "t: 30, diff: 0.0030700231354203744, self overlaps: 7.053861217664891, teacher-student overlap: 0.9552454815294906\n",
      "t: 31, diff: 0.00217023089425028, self overlaps: 7.054792533208953, teacher-student overlap: 0.9552758688728934\n",
      "t: 32, diff: 0.0015172222406588665, self overlaps: 7.05538097874728, teacher-student overlap: 0.955293150378927\n",
      "t: 33, diff: 0.0010484549653091424, self overlaps: 7.055741565053372, teacher-student overlap: 0.9553021834870377\n",
      "t: 34, diff: 0.0007154214263560554, self overlaps: 7.055953329793284, teacher-student overlap: 0.9553061820128117\n",
      "t: 35, diff: 0.0004814491567637358, self overlaps: 7.056070009135297, teacher-student overlap: 0.9553072425510918\n",
      "t: 36, diff: 0.00032004985451306034, self overlaps: 7.056127594567025, teacher-student overlap: 0.9553067021193717\n",
      "t: 37, diff: 0.00021006400594136831, self overlaps: 7.056149727078123, teacher-student overlap: 0.9553053847948775\n",
      "t: 38, diff: 0.00013509745207185286, self overlaps: 7.0561517047704125, teacher-student overlap: 0.9553037844938361\n",
      "t: 39, diff: 0.00010183934332275157, self overlaps: 7.056143133969173, teacher-student overlap: 0.955302178396882\n",
      "t: 40, diff: 7.783246729964333e-05, self overlaps: 7.056129906772544, teacher-student overlap: 0.9553007114657215\n",
      "t: 41, diff: 5.866661946307694e-05, self overlaps: 7.0561154376153885, teacher-student overlap: 0.9552994437249298\n",
      "t: 42, diff: 4.367881336064805e-05, self overlaps: 7.056101576678158, teacher-student overlap: 0.9552983883692756\n",
      "t: 43, diff: 3.21269414558234e-05, self overlaps: 7.056089276965903, teacher-student overlap: 0.9552975370186818\n",
      "t: 44, diff: 2.3364955493487827e-05, self overlaps: 7.056078849194279, teacher-student overlap: 0.9552968644144468\n",
      "t: 45, diff: 1.6832815735057238e-05, self overlaps: 7.056070288040548, teacher-student overlap: 0.9552963422286465\n",
      "t: 46, diff: 1.199257608797133e-05, self overlaps: 7.056063427039938, teacher-student overlap: 0.955295942288384\n",
      "t: 47, diff: 8.42195633854459e-06, self overlaps: 7.056058103142568, teacher-student overlap: 0.9552956452445571\n",
      "t: 48, diff: 5.890689879883837e-06, self overlaps: 7.056053968266316, teacher-student overlap: 0.9552954213672458\n",
      "t: 49, diff: 4.054939611197739e-06, self overlaps: 7.056050834940317, teacher-student overlap: 0.9552952571062467\n",
      "t: 50, diff: 2.744077141070278e-06, self overlaps: 7.056048504314638, teacher-student overlap: 0.9552951389341129\n",
      "t: 51, diff: 1.847900481966036e-06, self overlaps: 7.0560467624192835, teacher-student overlap: 0.9552950526412027\n",
      "t: 52, diff: 1.435630145985023e-06, self overlaps: 7.056045498993343, teacher-student overlap: 0.9552949920989163\n",
      "t: 53, diff: 1.1442387667370824e-06, self overlaps: 7.056044575745046, teacher-student overlap: 0.9552949485626752\n",
      "t: 54, diff: 8.831963068667292e-07, self overlaps: 7.056043916105658, teacher-student overlap: 0.9552949184414207\n",
      "t: 55, diff: 7.069547477422944e-07, self overlaps: 7.056043426558355, teacher-student overlap: 0.955294896025114\n",
      "t: 56, diff: 5.054559555350835e-07, self overlaps: 7.056043102476572, teacher-student overlap: 0.9552948822400447\n",
      "t: 57, diff: 3.7816388487321717e-07, self overlaps: 7.056042872462117, teacher-student overlap: 0.9552948727222379\n",
      "t: 58, diff: 2.7959546167188876e-07, self overlaps: 7.056042718233108, teacher-student overlap: 0.9552948667481107\n",
      "t: 59, diff: 1.811491223691064e-07, self overlaps: 7.056042623843801, teacher-student overlap: 0.95529486354751\n",
      "t: 60, diff: 1.5006260967176388e-07, self overlaps: 7.056042551862628, teacher-student overlap: 0.9552948607205072\n",
      "t: 61, diff: 7.78161937109445e-08, self overlaps: 7.056042519126387, teacher-student overlap: 0.9552948602163254\n",
      "Saddle point equations converged with t=62 iterations\n"
     ]
    }
   ],
   "source": [
    "sp.iterate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voila, now you can check the result with method `get_info`, which gives everything you might be interested in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hyperparameters': {'initialisation': 'uninformed',\n",
       "  'damping': 0.5,\n",
       "  'max_steps': 1000,\n",
       "  'tolerance': 1e-07},\n",
       " 'status': 1,\n",
       " 'convergence_time': 62,\n",
       " 'test_error': 0.38159910433570304,\n",
       " 'train_loss': 0.10475628623477738,\n",
       " 'overlaps': {'variance': 19.64921588846874,\n",
       "  'self_overlap': 7.056042551862628,\n",
       "  'teacher_student': 0.9552948607205072}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.get_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Custom data model: whole learning curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is boring to repeat all the pipeline above every time you want to compute a new $\\alpha$. Instead, we can encapsulate it in an `experiment` class which allows one to compute a whole learning curve in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from state_evolution.experiments.learning_curve import CustomExperiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class `CustomExperiment` takes as argument the task you want (from those implemented), the regularisation and the data_model, apart from all the hyperparameters of the iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_experiment = CustomExperiment(task = 'logistic_regression', \n",
    "                                 regularisation = 0.01, \n",
    "                                 data_model = data_model, \n",
    "                                 initialisation='uninformed', \n",
    "                                 tolerance = 1e-7, \n",
    "                                 damping = 0.5, \n",
    "                                 verbose = True, \n",
    "                                 max_steps = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the learning curve, you need to pass a python iterable with the values of the sample complexity you want to compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runninig sample complexity: 0.5\n",
      "Runninig sample complexity: 1\n",
      "Runninig sample complexity: 1.5\n"
     ]
    }
   ],
   "source": [
    "my_experiment.learning_curve(alphas = [0.5, 1, 1.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `.get_curve()` returns the learning curve as a `pandas.DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>gamma</th>\n",
       "      <th>lambda</th>\n",
       "      <th>rho</th>\n",
       "      <th>sample_complexity</th>\n",
       "      <th>V</th>\n",
       "      <th>m</th>\n",
       "      <th>q</th>\n",
       "      <th>test_error</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.979099</td>\n",
       "      <td>0.5</td>\n",
       "      <td>19.649216</td>\n",
       "      <td>0.955295</td>\n",
       "      <td>7.056043</td>\n",
       "      <td>0.381599</td>\n",
       "      <td>0.104756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.979099</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.289259</td>\n",
       "      <td>1.437530</td>\n",
       "      <td>9.174395</td>\n",
       "      <td>0.340768</td>\n",
       "      <td>0.156268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.979099</td>\n",
       "      <td>1.5</td>\n",
       "      <td>6.450970</td>\n",
       "      <td>1.619751</td>\n",
       "      <td>9.108898</td>\n",
       "      <td>0.317524</td>\n",
       "      <td>0.204456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  task  gamma  lambda       rho  sample_complexity          V  \\\n",
       "0  logistic_regression    0.5    0.01  0.979099                0.5  19.649216   \n",
       "1  logistic_regression    0.5    0.01  0.979099                1.0  10.289259   \n",
       "2  logistic_regression    0.5    0.01  0.979099                1.5   6.450970   \n",
       "\n",
       "          m         q  test_error  train_loss  \n",
       "0  0.955295  7.056043    0.381599    0.104756  \n",
       "1  1.437530  9.174395    0.340768    0.156268  \n",
       "2  1.619751  9.108898    0.317524    0.204456  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_experiment.get_curve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note you can save it in a csv, you can just call the method `save_experiment`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_experiment.save_experiment(name='testing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: defining a model directly as a function of the specta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that even though an instance of the Gaussian covariate model is defined by $(\\Psi, \\Phi, \\Omega, \\theta_{0})$, the saddle-point equations can be closed on the following scalar quantities:\n",
    "\\begin{align}\n",
    "\\rho = \\frac{1}{p}\\theta_{0}^{\\top}\\Psi\\theta_{0}, && \\omega_{i}\\in \\rm{spec}(\\Omega), && t_{i} = \\left(U^{\\top}\\Phi^{\\top}\\theta_{0}\\theta_{0}^{\\top}\\Phi U\\right)_{ii}, && i=1, \\cdots, d\n",
    "\\end{align}\n",
    "where $\\rm{spec}(\\Omega)$ are the eigenvalues of $\\Omega$ and $U\\in\\mathbb{R}^{d\\times d}$ are the eigenvectors of $\\Omega$. \n",
    "\n",
    "Therefore, we can also define our `data_model` by directly passing these quantities to the class `CustomSpectra`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from state_evolution.data_models.custom import CustomSpectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the spectrum\n",
      "Projection in student basis\n",
      "Computing rho\n"
     ]
    }
   ],
   "source": [
    "print('Computing the spectrum')\n",
    "spec_Omega, U = np.linalg.eigh(Omega)\n",
    "\n",
    "print('Projection in student basis')\n",
    "t = np.diagonal(U.T @ Phi.T @ theta.reshape(p, 1) @ theta.reshape(1, p) @ Phi @ U)\n",
    "\n",
    "print('Computing rho')\n",
    "rho = 1/p * theta.dot(Psi @ theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that $\\rho\\in\\mathbb{R}$, but both $\\{\\omega_{i}\\}_{i=1}^{d}$ and $\\{t_{i}\\}_{i=1}^{d}$ are $d$-dimensional quantities. Therefore, we will also need to pass $\\gamma = p/d$ to our `data_model` in order to run the saddle-point equations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model_spec = CustomSpectra(rho = rho, \n",
    "                                spec_Omega = spec_Omega, \n",
    "                                diagonal_term = t,\n",
    "                                gamma = p/d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runninig sample complexity: 0.5\n"
     ]
    }
   ],
   "source": [
    "my_experiment = CustomExperiment(task = 'logistic_regression', \n",
    "                                 regularisation = 0.01, \n",
    "                                 data_model = data_model_spec, \n",
    "                                 initialisation='uninformed', \n",
    "                                 tolerance = 1e-7, \n",
    "                                 damping = 0.5, \n",
    "                                 verbose = True, \n",
    "                                 max_steps = 1000)\n",
    "\n",
    "my_experiment.learning_curve(alphas = [0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
